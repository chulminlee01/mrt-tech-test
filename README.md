# ğŸ¤– Myrealtrip Tech Test Generator

> AI crews plan, discuss, and ship ready-to-use take-home assignments with datasets, starter code, and a branded candidate portal.

## ğŸŒ Live Demo
- **Production (Railway):** https://mrt-tech-test-production.up.railway.app/
- **Local:** `./start_webapp.sh` â†’ http://localhost:8080

## âœ¨ Highlights
- **Hierarchical CrewAI workflow** with PM, Research, Assignment Generator, QA, Data, Web Builder, and Web Designer roles collaborating in sequence.
- **Single flagship assignment** per run so candidates focus on the most relevant scenario for the chosen role & level.
- **Realtime visualization**: timeline chat, agent focus banner, Google CSE tool badges, and long-task tracker with elapsed timer + step indicators.
- **LLM selector in the UI**: defaults to OpenRouter's `x-ai/grok-4.1-fast`, but you can switch to NVIDIA Qwen, DeepSeek, or Llama without editing code.
- **Automatic assets**: synthetic datasets, starter code bundles, localized candidate portal, styling, and downloadable links regenerated after every run.
- **Resilient orchestration**: heartbeats during long tasks, per-job logging, fallback model chain, and cleaned-up repo (no generated artifacts tracked).

## ğŸš€ Quick Start
```bash
# 1. Clone & enter
 git clone https://github.com/chulminlee01/mrt-tech-test.git
cd mrt-tech-test

# 2. Python 3.10+ virtual env
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install deps
 pip install --upgrade pip
pip install -r requirements.txt

# 4. Configure secrets
cp .env.example .env
 $EDITOR .env  # add API keys (see below)

# 5. Run locally (port 8080)
./start_webapp.sh
# or
 python app.py
```
Visit http://localhost:8080 and watch the crew do the work.

## ğŸ”‘ Environment Variables
| Variable | Purpose | Required |
| --- | --- | --- |
| `OPENROUTER_API_KEY` | Needed for the default Grok 4.1 Fast crew model | âœ… (unless you override `DEFAULT_MODEL` with NVIDIA) |
| `DEFAULT_MODEL` | Primary LLM (UI dropdown is pre-populated with this). Defaults to `x-ai/grok-4.1-fast`. | â– |
| `OPENROUTER_SITE_URL` / `OPENROUTER_APP_NAME` | Optional attribution headers | â– |
| `NVIDIA_API_KEY` | Enables NVIDIA models (`qwen/qwen3-next-80b-a3b-instruct`, `deepseek-ai/deepseek-v3.1-terminus`, etc.) | â– |
| `NVIDIA_FALLBACK_MODEL` | Secondary NVIDIA model if the first choice times out | â– |
| `GOOGLE_API_KEY`, `GOOGLE_CSE_ID` | Required for the Research Analyst to run Google CSE searches | â– (adds better research) |
| `PORT` | Override the Flask port (default 8080, Railway injects one) | â– |

## ğŸ§  Workflow
1. **PM** announces the goal and delegates research.
2. **Research Analyst** runs Google CSE (with citations) and shares summarized insights.
3. **PM + crew** align on skill focus areas; QA approves the plan.
4. **Assignment Generator** produces one JSON assignment aligned with the research + language selection.
5. **Data Provider** writes OTA-flavored datasets; **Web Builder** assembles the portal; **Starter code** is generated for the exact assignment.
6. **Web Designer** applies Myrealtrip branding; QA and PM sign off and the portal link becomes available.

## ğŸ“¦ Output Bundle
```
output/frontend_developer_mid_level_20251121_125033/
â”œâ”€â”€ research_report.txt          # Research summary + citations
â”œâ”€â”€ assignments.json             # Single flagship assignment (structured)
â”œâ”€â”€ datasets/                    # JSON/CSV data referenced by the task
â”‚   â””â”€â”€ ...
â”œâ”€â”€ starter_code/                # Language-specific starter kit
â”‚   â””â”€â”€ assignment_01_starter.tsx
â”œâ”€â”€ index.html                   # Candidate-facing portal
â”œâ”€â”€ styles.css                   # Theme generated by Web Designer
â””â”€â”€ design_notes.md              # Styling notes & guidance
```
Each dataset and starter file is surfaced on the portal with working download links.

## ğŸ› ï¸ Components
- `app.py` â€“ Flask API + log capture, long-task heartbeats, per-job state.
- `templates/index.html` â€“ Modern UI (timeline, focus banner, LLM selector, completed link).
- `crewai_working.py` â€“ Simple deterministic pipeline (default) + optional hierarchical CrewAI fallback.
- `agent_*` modules â€“ Specialized generators for questions, datasets, starter code, and portal.
- `llm_client.py` â€“ Provider-aware client with explicit model selection + fallbacks (OpenRouter â†” NVIDIA).

## ğŸ§± Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     fetch               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser UI  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º      â”‚        Flask API         â”‚
â”‚ (index.html) â”‚   /api/generate        â”‚        (app.py)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²             /api/status/logs                     â”‚
        â”‚                                                 â”‚ kicks off
        â”‚ websockets not needed                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Deterministic Crew Pipeline (crewai_working.py)           â”‚
â”‚                                                                    â”‚
â”‚  PM kickoff â†’ Research LLM â†’ Skill alignment â†’ QA sign-off â†’       â”‚
â”‚  Assignment generator (agent_question_generator.py)                â”‚
â”‚  Data provider (agent_data_provider.py)                            â”‚
â”‚  Starter code builder (agent_starter_code.py)                      â”‚
â”‚  Portal builder + designer (agent_web_builder.py / agent_web_designer.py) â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ writes artifacts
                            â–¼
                  `output/<role>_<level>_<timestamp>/`
                     â”œâ”€â”€ research_report.txt
                     â”œâ”€â”€ assignments.json
                     â”œâ”€â”€ datasets/
                     â”œâ”€â”€ starter_code/
                     â”œâ”€â”€ index.html + styles.css + design_notes.md
                            â”‚
                            â–¼
                 Served back to the UI as a download link
```

- **State tracking:** `app.py` captures stdout from every agent log and keeps an in-memory `generation_status` record per job (progress label, active agent, portal path, elapsed time).
- **Heartbeats:** Long-running tasks (starter code, styling) wrap their work in `_run_with_heartbeat`, so every 25 seconds the backend emits â€œstill workingâ€ logs the UI can display.
- **Model abstraction:** All LLM calls route through `llm_client.py`, which honors the UI dropdown choice and automatically falls back through NVIDIA and OpenRouter chains.
- **Artifact integrity:** After starter code finishes, the portal is rebuilt to ensure all download links point to real files before styling is applied.

## ğŸ¤ CrewAI Example Run
The timeline below mirrors the actual logs captured in `crewai_working.py` and rendered in the UI.

| Time | Agent | What happens |
|------|-------|--------------|
| 00:00 | ğŸ‘” PM | `Team, we're preparing a tech assignment for Senior Frontend Developer...` |
| 00:05 | ğŸ” Research Analyst | `Investigating best practices...` + Google CSE citations like `(å‚è€ƒ: igotanoffer.com)` |
| 01:00 | ğŸ‘” PM | `Aligning on skill focus areas with team...` |
| 01:10 | âœï¸ Assignment Generator | `I'll craft one flagship assignment... Assignment Generator is crafting scenario variations...` |
| 02:00 | ğŸ“Š Data Provider | `Generated dataset for assignment -> .../datasets/hotels.json` (repeated per dataset) |
| 02:30 | ğŸŒ Web Builder | `Building candidate portal... I'll create a professional HTML portal with all assignment details.` |
| 02:45 | ğŸ¨ Web Designer | `Applying Myrealtrip branding... Styling applied.` |
| 03:00 | ğŸ” QA + ğŸ‘” PM | `Final review - All deliverables look excellent!` â†’ `FINAL APPROVAL: Portal ready for candidates. Great teamwork! ğŸ‰` |
| 03:05 | ğŸŒ Web Builder | `Generating starter code bundle for the portal...` (heartbeats every ~25s) â†’ `Final assets ready. Publishing portal link...` |

Those logs simultaneously update the crew grid, timeline, focus banner, and the discussion modal so users can see the entire process in-context.

## â˜ï¸ Deployment
### Railway (current production)
The repo includes `railway.json`, `render.yaml`, and helper scripts. The live deployment runs on Railway and can be accessed here:
- https://mrt-tech-test-production.up.railway.app/

Deploy your own instance:
```bash
railway login
railway up
# or use ./deploy_railway.sh for scripted deploys
```
Environment variables are pulled from Railway's dashboard; remember to add your API keys there.

### Local / Docker
- `./start_webapp.sh` (Mac/Linux) or `python app.py` (any OS).
- `Dockerfile` is available if you want a containerized run (e.g., `docker build -t mrt-tech-test .`).

## ğŸ“š Documentation
All historical and deep-dive docs now live in `docs/` (moved out of the root for clarity):
- `docs/ARCHITECTURE.md` â€“ extended diagrams, sequence charts, and data contracts.
- `docs/DEPLOYMENT_GUIDE.md`, `docs/RAILWAY_DEPLOY.md`, `docs/READY_TO_USE.md` â€“ deployment playbooks.
- `docs/TROUBLESHOOTING.md`, `docs/URGENT_FIX.md`, etc. â€“ past incidents and fixes.

## ğŸ Troubleshooting
- **Stuck on "Finalizing deliverables"?** Check the long-task banner: it shows elapsed time + step. The backend emits heartbeats every 25s.
- **No download links?** Ensure starter code generation finished; the portal is rebuilt after starter code completes.
- **Research agent quiet?** Verify `GOOGLE_API_KEY` + `GOOGLE_CSE_ID`. Without them, the app falls back to general knowledge and logs a warning.
- **LLM errors?** Choose a different model from the dropdown or set `NVIDIA_API_KEY` so the fallback chain has more options.
