# ğŸ¤– Myrealtrip Tech Test Generator

> AI crews plan, discuss, and ship ready-to-use take-home assignments with datasets, starter code, and a branded candidate portal.

## ğŸŒ Live Demo
- **Production (Railway):** https://mrt-tech-test-production.up.railway.app/
- **Local:** `./start_webapp.sh` â†’ http://localhost:8080

## âœ¨ Highlights
- **Hierarchical CrewAI workflow** with PM, Research, Assignment Generator, QA, Data, Web Builder, and Web Designer roles collaborating in sequence.
- **Single flagship assignment** per run so candidates focus on the most relevant scenario for the chosen role & level.
- **Realtime visualization**: timeline chat, agent focus banner, Google CSE tool badges, and long-task tracker with elapsed timer + step indicators.
- **LLM selector in the UI**: defaults to OpenRouter's `x-ai/grok-4.1-fast`, but you can switch to NVIDIA Qwen, DeepSeek, or Llama without editing code.
- **Automatic assets**: synthetic datasets, starter code bundles, localized candidate portal, styling, and downloadable links regenerated after every run.
- **Resilient orchestration**: heartbeats during long tasks, per-job logging, fallback model chain, and cleaned-up repo (no generated artifacts tracked).

## ğŸš€ Quick Start
```bash
# 1. Clone & enter
 git clone https://github.com/chulminlee01/mrt-tech-test.git
cd mrt-tech-test

# 2. Python 3.10+ virtual env
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install deps
 pip install --upgrade pip
pip install -r requirements.txt

# 4. Configure secrets
cp .env.example .env
 $EDITOR .env  # add API keys (see below)

# 5. Run locally (port 8080)
./start_webapp.sh
# or
 python app.py
```
Visit http://localhost:8080 and watch the crew do the work.

## ğŸ”‘ Environment Variables
| Variable | Purpose | Required |
| --- | --- | --- |
| `OPENROUTER_API_KEY` | Needed for the default Grok 4.1 Fast crew model | âœ… (unless you override `DEFAULT_MODEL` with NVIDIA) |
| `DEFAULT_MODEL` | Primary LLM (UI dropdown is pre-populated with this). Defaults to `x-ai/grok-4.1-fast`. | â– |
| `OPENROUTER_SITE_URL` / `OPENROUTER_APP_NAME` | Optional attribution headers | â– |
| `NVIDIA_API_KEY` | Enables NVIDIA models (`qwen/qwen3-next-80b-a3b-instruct`, `deepseek-ai/deepseek-v3.1-terminus`, etc.) | â– |
| `NVIDIA_FALLBACK_MODEL` | Secondary NVIDIA model if the first choice times out | â– |
| `GOOGLE_API_KEY`, `GOOGLE_CSE_ID` | Required for the Research Analyst to run Google CSE searches | â– (adds better research) |
| `PORT` | Override the Flask port (default 8080, Railway injects one) | â– |

## ğŸ§  Workflow
1. **PM** announces the goal and delegates research.
2. **Research Analyst** runs Google CSE (with citations) and shares summarized insights.
3. **PM + crew** align on skill focus areas; QA approves the plan.
4. **Assignment Generator** produces one JSON assignment aligned with the research + language selection.
5. **Data Provider** writes OTA-flavored datasets; **Web Builder** assembles the portal; **Starter code** is generated for the exact assignment.
6. **Web Designer** applies Myrealtrip branding; QA and PM sign off and the portal link becomes available.

## ğŸ“¦ Output Bundle
```
output/frontend_developer_mid_level_20251121_125033/
â”œâ”€â”€ research_report.txt          # Research summary + citations
â”œâ”€â”€ assignments.json             # Single flagship assignment (structured)
â”œâ”€â”€ datasets/                    # JSON/CSV data referenced by the task
â”‚   â””â”€â”€ ...
â”œâ”€â”€ starter_code/                # Language-specific starter kit
â”‚   â””â”€â”€ assignment_01_starter.tsx
â”œâ”€â”€ index.html                   # Candidate-facing portal
â”œâ”€â”€ styles.css                   # Theme generated by Web Designer
â””â”€â”€ design_notes.md              # Styling notes & guidance
```
Each dataset and starter file is surfaced on the portal with working download links.

## ğŸ› ï¸ Components
- `app.py` â€“ Flask API + log capture, long-task heartbeats, per-job state.
- `templates/index.html` â€“ Modern UI (timeline, focus banner, LLM selector, completed link).
- `crewai_working.py` â€“ Simple deterministic pipeline (default) + optional hierarchical CrewAI fallback.
- `agent_*` modules â€“ Specialized generators for questions, datasets, starter code, and portal.
- `llm_client.py` â€“ Provider-aware client with explicit model selection + fallbacks (OpenRouter â†” NVIDIA).

## â˜ï¸ Deployment
### Railway (current production)
The repo includes `railway.json`, `render.yaml`, and helper scripts. The live deployment runs on Railway and can be accessed here:
- https://mrt-tech-test-production.up.railway.app/

Deploy your own instance:
```bash
railway login
railway up
# or use ./deploy_railway.sh for scripted deploys
```
Environment variables are pulled from Railway's dashboard; remember to add your API keys there.

### Local / Docker
- `./start_webapp.sh` (Mac/Linux) or `python app.py` (any OS).
- `Dockerfile` is available if you want a containerized run (e.g., `docker build -t mrt-tech-test .`).

## ğŸ Troubleshooting
- **Stuck on "Finalizing deliverables"?** Check the long-task banner: it shows elapsed time + step. The backend emits heartbeats every 25s.
- **No download links?** Ensure starter code generation finished; the portal is rebuilt after starter code completes.
- **Research agent quiet?** Verify `GOOGLE_API_KEY` + `GOOGLE_CSE_ID`. Without them, the app falls back to general knowledge and logs a warning.
- **LLM errors?** Choose a different model from the dropdown or set `NVIDIA_API_KEY` so the fallback chain has more options.
